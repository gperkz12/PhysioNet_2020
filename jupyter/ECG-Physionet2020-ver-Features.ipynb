{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing # classification\n",
    "from itertools import chain \n",
    "\n",
    "# FEATURE ENGINEERING\n",
    "from ecgdetectors import Detectors\n",
    "\n",
    "# CLASSIFICATION\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENVIRONMENT\n",
    "# tf2_gpu\n",
    "\n",
    "\n",
    "# physionet data\n",
    "pth_data = r'C:\\Users\\muham\\Documents\\rizwan-asus\\DATA\\PHYSIONET-2020\\data1\\Training_WFDB'\n",
    "\n",
    "# pth_code = r'C:\\Users\\muham\\Documents\\rizwan-asus\\PHYSIONET2020\\code\\physionet-python-2020-master'\n",
    "\n",
    "pth_functions = r'C:\\Users\\muham\\Documents\\rizwan-asus\\PHYSIONET2020\\code\\PhysioNet_2020'\n",
    "\n",
    "pth_eval = r'C:\\Users\\muham\\Documents\\rizwan-asus\\PHYSIONET2020\\results'\n",
    "\n",
    "pth_res = r'C:\\Users\\muham\\Documents\\rizwan-asus\\PHYSIONET2020\\results\\res1'\n",
    "\n",
    "pth_fig = r'C:\\Users\\muham\\Documents\\rizwan-asus\\PHYSIONET2020\\figures'\n",
    "\n",
    "pth_pwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GITHUB CODE\n",
    "# os.chdir(pth_code)\n",
    "\n",
    "# from driver import *\n",
    "# from get_12ECG_features import *\n",
    "# from run_12ECG_classifier import *\n",
    "\n",
    "# LOCAL FUNCTIONS\n",
    "os.chdir(pth_functions)\n",
    "\n",
    "# PHYSIONET FUNCTIONS\n",
    "from driver import *\n",
    "from get_12ECG_features import *\n",
    "from run_12ECG_classifier import *\n",
    "\n",
    "# RIZ FUNCTIONS\n",
    "from data_read import data_files_list\n",
    "from data_read import data_files_load\n",
    "\n",
    "from data_preprocess import *\n",
    "from data_prepare import *\n",
    "from plt_ecg import *\n",
    "\n",
    "os.chdir(pth_pwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_peaks_idx2sample(r_peaks_idx,skip_direction = 'left',skip_values =2):\n",
    "    \"\"\"convert r-peaks indexes to peak-peak in terms of sample\"\"\"\n",
    "    # skip_values = 2\n",
    "    # skip_direction = 'both' # 'left', 'right', 'both'\n",
    "    \n",
    "    if(skip_direction == 'left'):\n",
    "        r_idx_diff = np.diff(r_peaks_idx)[skip_values:]\n",
    "    elif(skip_direction == 'right'):\n",
    "        r_idx_diff = np.diff(r_peaks_idx)[:-skip_values]\n",
    "    elif(skip_direction == 'both'):\n",
    "        r_idx_diff = np.diff(r_peaks_idx)[skip_values:-skip_values]\n",
    "    else: # default - 'left'\n",
    "        r_idx_diff = np.diff(r_peaks_idx)[skip_values:]\n",
    "        \n",
    "    return r_idx_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_no = 1 # index of the data sample\n",
    "lead_no = 1 # 12-lead ECG waveform (1,2,3,... 12)\n",
    "\n",
    "TOT_LEADS = 12\n",
    "OUTPUT_CLASSES = 9\n",
    "\n",
    "ANOMALIES_REMOVAL = False\n",
    "NOISE_REMOVAL = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### List of data files ```data_read.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of input files:  6877\n",
      "A0001.mat\n"
     ]
    }
   ],
   "source": [
    "input_files = data_files_list(pth_data)\n",
    "print('Total number of input files: ',len(input_files))\n",
    "\n",
    "print(input_files[sample_no-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of data and labels  ```data_read.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels from REFERENCE file\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-0add4663a2bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mlist_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlist_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlist_fname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_files_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpth_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# To get only 'First Label'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlist_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "[list_data,list_label,list_fname] = data_files_load(pth_data,'',False,True)\n",
    "\n",
    "# To get only 'First Label'\n",
    "list_label = [item[0] for item in list_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total Samples: ',len(list_label))\n",
    "label_tmp = np.array(list_label) \n",
    "\n",
    "print('Unique labels',len(np.unique(label_tmp))) \n",
    "del label_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA SPLIT \n",
    "1. Training Data: **```X_train``` & ```Y_train```**\n",
    "2. Validation Data: ```X_valid``` & ```Y_valid```\n",
    "3. Training Data: ```X_test``` & ```Y_test```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test subsets\n",
    "\n",
    "# Train data (60%) +  Validation data (20%) + Test data (20%)\n",
    "fname_train, fname_test, Y_train, Y_test = train_test_split(list_fname, list_label, test_size=0.2, shuffle=True,random_state=1)\n",
    "fname_train, fname_valid, Y_train, Y_valid = train_test_split(fname_train, Y_train, test_size=0.25, shuffle=True,random_state=1)\n",
    "\n",
    "# X_train - list of dimension samples x leads(12) x ecg signal\n",
    "# Y_train - list of dimension samples x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(fname_train),len(Y_train),len(fname_valid),len(Y_valid),len(fname_test),len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-385f9d6d645e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract meta-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_smp_name = list_fname[sample_no-1][:-4]\n",
    "\n",
    "print('ECG Sample Name:',tmp_smp_name)\n",
    "\n",
    "\n",
    "tmp_smp_mat = os.path.join(pth_data,tmp_smp_name+'.mat')\n",
    "tmp_smp_hea = os.path.join(pth_data,tmp_smp_name+'.hea')\n",
    "\n",
    "data, header_data = load_challenge_data(tmp_smp_mat)\n",
    "# data - ecg data\n",
    "# header_data - contains information such as fs, gain, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_hea = header_data[0].split(' ')\n",
    "# print(tmp_hea)\n",
    "# ['A0001', '12', '500', '7500', '16-Mar-2020', '19:07:01\\n']\n",
    "ptID = tmp_hea[0] # 'A0001'\n",
    "num_leads = int(tmp_hea[1]) # '12'\n",
    "sample_Fs= int(tmp_hea[2]) # '500'\n",
    "gain_lead = np.zeros(num_leads) # 1000\n",
    "\n",
    "for ii in range(num_leads):\n",
    "    tmp_hea = header_data[ii+1].split(' ')\n",
    "    gain_lead[ii] = int(tmp_hea[2].split('/')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing, we included the mean age of 57 if the age is a NaN\n",
    "# This value will change as more data is being released\n",
    "for iline in header_data:\n",
    "    if iline.startswith('#Age'):\n",
    "        tmp_age = iline.split(': ')[1].strip()\n",
    "        tmp_sample_age = int(tmp_age if tmp_age != 'NaN' else 57)\n",
    "    elif iline.startswith('#Sex'):\n",
    "        tmp_sex = iline.split(': ')[1]\n",
    "        if tmp_sex.strip()=='Female':\n",
    "            tmp_sample_sex =1\n",
    "        else:\n",
    "            tmp_sample_sex=0\n",
    "    elif iline.startswith('#Dx'):\n",
    "        label = iline.split(': ')[1].split(',')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(header_data)\n",
    "t1 = []\n",
    "t1.append(header_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_meta = np.hstack([tmp_sample_age,tmp_sample_sex,sample_Fs,gain_lead])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmp_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_sample_ecg_all = data # ECG from all the leads\n",
    "tmp_sample_ecg_lead = data[lead_no-1]\n",
    "tmp_sample_ecg_g = gain_lead[lead_no-1]\n",
    "tmp_sample_ecg_fs = sample_Fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sample (length): ',len(tmp_sample_ecg_lead))\n",
    "print('Sample (label): ',list_label[sample_no-1])\n",
    "print('Sample (gain): ',tmp_sample_ecg_g)\n",
    "print('Sample (sampling-frequency): ',tmp_sample_ecg_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sample - All (shape): ',np.shape(tmp_sample_ecg_all))\n",
    "print('Sample - Lead (shape): ',np.shape(tmp_sample_ecg_lead))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ECG Waveform\n",
    "\n",
    "__Parameters__\n",
    "\n",
    "- ```sample_no```\n",
    "- ```lead_no```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Lead    ```lead_no```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = plt.get_cmap('gist_rainbow')\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.plot(list_data[sample_no-1][lead_no-1,:],color='b',linestyle = '-' )\n",
    "\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "\n",
    "\n",
    "tmp_pth = os.path.join(pth_fig,'raw_single_lead',list_fname[sample_no-1][:-4])\n",
    "\n",
    "print('Raw figure path: ',tmp_pth)\n",
    "plt.savefig(tmp_pth+'_raw_l'+str(lead_no)+'.png',dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Lead "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_COLORS = 12 # Total Leads = 12\n",
    "LINE_STYLES = ['solid', 'dashed', 'dashdot', 'dotted']\n",
    "NUM_STYLES = len(LINE_STYLES)\n",
    "\n",
    "legend_lst = []\n",
    "cm = plt.get_cmap('gist_rainbow')\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "for i in range(NUM_COLORS):\n",
    "    lines = ax.plot(list_data[sample_no-1][i,:])\n",
    "    lines[0].set_color(cm(i//NUM_STYLES*float(NUM_STYLES)/NUM_COLORS))\n",
    "    lines[0].set_linestyle(LINE_STYLES[i%NUM_STYLES])\n",
    "    legend_lst.append('L'+str(i+1))\n",
    "\n",
    "ax.legend(legend_lst,loc='upper center', bbox_to_anchor=(0.5, -0.1), shadow=True, ncol=3)\n",
    "tmp_pth = os.path.join(pth_fig,'raw_multiple_leads',list_fname[sample_no-1][:-4])\n",
    "fig.savefig(tmp_pth+'_raw_multiple.png',dpi = 300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# plt_ecg_raw(list_data, pth_fig, '')\n",
    "\n",
    "plt_ecg_raw(list_data, list_fname, pth_fig, [1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### @vector\n",
    "\n",
    "- ```TO DO```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type I\n",
    "- removal of anomalies\n",
    "- removal of noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(ANOMALIES_REMOVAL):\n",
    "    print('ANOMALIES REMOVAL - DONE')\n",
    "    tmp_sample_sig = preprocess_type1(tmp_sample_ecg_all)\n",
    "    print(np.shape(tmp_sample_sig))\n",
    "    tmp_sample_preprocess = tmp_sample_sig[0,0,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(NOISE_REMOVAL):\n",
    "    print('To Do')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure()\n",
    "plt.plot(tmp_sample_preprocess,'g')\n",
    "plt.title('Preprocess Signal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-peaks: ```physionet```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r_peaks_pnet,r_idx_pnet = detect_peaks(tmp_sample_ecg_lead,tmp_sample_ecg_fs,tmp_sample_ecg_g)\n",
    "# r_peaks_pnet - peak values based on physionet algorithm\n",
    "# r_idx_pnet - peak indices based on physionet algorithm\n",
    "\n",
    "r_peaks_pnet = r_peaks_pnet.astype(int)\n",
    "r_idx_pnet_sample = r_peaks_idx2sample(r_idx_pnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r_peaks_pnet)\n",
    "print(r_idx_pnet)\n",
    "\n",
    "print(len(r_peaks_pnet))\n",
    "print(len(r_idx_pnet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   mean\n",
    "mean_RR = np.mean(r_idx_pnet/tmp_sample_ecg_fs*1000)\n",
    "mean_Peaks = np.mean(r_peaks_pnet)\n",
    "\n",
    "print(mean_RR)\n",
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-peaks: ```py-ecg-detector```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detectors = Detectors(tmp_sample_ecg_fs)\n",
    "\n",
    "tmp_ecg_integ = ecg_sig_integrated(tmp_sample_ecg_lead,tmp_sample_ecg_fs)\n",
    "tmp_input_features = tmp_sample_ecg_lead\n",
    "\n",
    "\n",
    "# Hamilton\n",
    "r_idx_hamilton = detectors.hamilton_detector(tmp_input_features) \n",
    "r_idx_hamilton_sample = r_peaks_idx2sample(r_idx_hamilton)\n",
    "# r_peaks_hamilton = tmp_ecg_integ[r_idx_hamilton]\n",
    "\n",
    "# Christov\n",
    "r_idx_christov = detectors.christov_detector(tmp_input_features)\n",
    "# r_peaks_christov = tmp_ecg_integ[r_idx_christov]\n",
    "\n",
    "# Engelse & Zeelenberg\n",
    "r_idx_engelse = detectors.engzee_detector(tmp_input_features)\n",
    "# r_peaks_engelse = tmp_ecg_integ[r_idx_engelse]\n",
    "\n",
    "# Pan & Tompkins\n",
    "r_idx_pan = detectors.pan_tompkins_detector(tmp_input_features)\n",
    "# r_peaks_pan = tmp_ecg_integ[r_idx_pan]\n",
    "\n",
    "# Stationary Wavelet Transform\n",
    "r_idx_wavelet = detectors.swt_detector(tmp_input_features)\n",
    "# r_peaks_wavelet = tmp_ecg_integ[r_idx_wavelet]\n",
    "\n",
    "#Two Moving Average\n",
    "r_idx_mavg = detectors.two_average_detector(tmp_input_features)\n",
    "# r_peaks_mavg = tmp_ecg_integ[r_idx_mavg]\n",
    "\n",
    "# Matched Filter\n",
    "# r_peaks_mfilter = detectors.matched_filter_detector(tmp_sample_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```pyhrv```"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from pyhrv.hrv import hrv\n",
    "from pyhrv.time_domain import nn20, nn50, sdnn, sdsd, rmssd, hr_parameters\n",
    "from pyhrv.frequency_domain import frequency_domain\n",
    "from pyhrv.tools import nn_intervals, time_varying, heart_rate_heatplot, plot_ecg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```heartpy```"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import heartpy as hp\n",
    "#run analysis\n",
    "wd, m = hp.process(tmp_sample_ecg_lead, tmp_sample_ecg_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```WIP```\n",
    "\n",
    "- matplotlib==2.2.2\n",
    "- ipywidgets==7.2.1\n",
    "- scipy==1.0.1\n",
    "- numpy==1.14.2\n",
    "- pandas==0.22.0\n",
    "- biosppy\n",
    "- pyentrp\n",
    "- pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import local Libraries\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "from features.feature_extractor import Features\n",
    "from ecg_features.utils.plotting.waveforms import plot_waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "r_idx_tmp1 = r_peaks_idx2sample(r_idx_hamilton)\n",
    "mean_RR_interval = np.mean(r_idx_tmp1)\n",
    "print(mean_RR_interval)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(np.mean(r_idx_hamilton))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heartrate Variability Analysis"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "HRV.HR(r_idx_pan)\n",
    "#    Calculate heart-rates from R peak samples"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from hrv import HRV\n",
    "help(hrv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot - ```r-peak```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_PEAK_DETECTION = 'pan'\n",
    "# 'pnet','hamilton', 'christov', 'engelse', 'pan','wavelet', 'mavg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(tmp_input_features)\n",
    "if(R_PEAK_DETECTION == 'pnet'): \n",
    "    plt.plot(r_peaks_pnet, tmp_input_features[r_peaks_hamilton], 'ro')\n",
    "elif(R_PEAK_DETECTION == 'hamilton'): \n",
    "    plt.plot(r_peaks_hamilton, tmp_input_features[r_peaks_hamilton], 'ro')\n",
    "elif(R_PEAK_DETECTION == 'christov'): \n",
    "    plt.plot(r_peaks_christov, tmp_input_features[r_peaks_christov], 'ro')\n",
    "elif(R_PEAK_DETECTION == 'engelse'): \n",
    "    plt.plot(r_peaks_engelse, tmp_input_features[r_peaks_engelse], 'ro')\n",
    "elif(R_PEAK_DETECTION == 'pan'): \n",
    "    plt.plot(r_idx_pan, tmp_input_features[r_idx_pan], 'ro')\n",
    "elif(R_PEAK_DETECTION == 'wavelet'): \n",
    "    plt.plot(r_peaks_wavelet, tmp_input_features[r_peaks_wavelet], 'ro')\n",
    "elif(R_PEAK_DETECTION == 'mavg'): \n",
    "    plt.plot(r_peaks_mavg, tmp_input_features[r_peaks_mavg], 'ro')\n",
    "    \n",
    "plt.title('Detected R-peaks')\n",
    "# plt.show()\n",
    "\n",
    "tmp_pth = os.path.join(pth_fig,list_fname[sample_no-1][:-4]+'_lead'+str(lead_no)+'_rpeak_'+R_PEAK_DETECTION)\n",
    "\n",
    "print('Raw figure path: ',tmp_pth)\n",
    "plt.savefig(tmp_pth+'.png',dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   mean\n",
    "mean_RR = np.mean(r_idx_pnet_sample/tmp_sample_ecg_fs)\n",
    "mean_Peaks = np.mean(r_peaks_pnet*tmp_sample_ecg_g)\n",
    "\n",
    "#   median\n",
    "median_RR = np.median(r_idx_pnet_sample/tmp_sample_ecg_fs)\n",
    "median_Peaks = np.median(r_peaks_pnet*tmp_sample_ecg_g)\n",
    "\n",
    "#   standard deviation\n",
    "std_RR = np.std(r_idx_pnet_sample/tmp_sample_ecg_fs*1000)\n",
    "std_Peaks = np.std(r_peaks_pnet*tmp_sample_ecg_g)\n",
    "\n",
    "#   variance\n",
    "var_RR = stats.tvar(r_idx_pnet_sample/tmp_sample_ecg_fs*1000)\n",
    "var_Peaks = stats.tvar(r_peaks_pnet*tmp_sample_ecg_g)\n",
    "\n",
    "#   Skewness\n",
    "skew_RR = stats.skew(r_idx_pnet_sample/tmp_sample_ecg_fs*1000)\n",
    "skew_Peaks = stats.skew(r_peaks_pnet*tmp_sample_ecg_g)\n",
    "\n",
    "#   Kurtosis\n",
    "kurt_RR = stats.kurtosis(r_idx_pnet_sample/tmp_sample_ecg_fs*1000)\n",
    "kurt_Peaks = stats.kurtosis(r_peaks_pnet*tmp_sample_ecg_g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_samp = np.hstack([tmp_sample_age,tmp_sample_sex,mean_RR,mean_Peaks,median_RR,median_Peaks,std_RR,std_Peaks,var_RR,var_Peaks,skew_RR,skew_Peaks,kurt_RR,kurt_Peaks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(features_samp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_samp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TEMP: Backup of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_bup = Y_train.copy()\n",
    "X_train_bup = X_train.copy()\n",
    "\n",
    "Y_valid_bup = Y_valid.copy()\n",
    "X_valid_bup = X_valid.copy()\n",
    "\n",
    "Y_test_bup = Y_test.copy()\n",
    "X_test_bup = X_test.copy()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Y_train= Y_train.copy()\n",
    "X_train = X_train.copy()\n",
    "\n",
    "Y_valid_ = Y_valid.copy()\n",
    "X_valid_bup = X_valid.copy()\n",
    "\n",
    "Y_test_bup = Y_test.copy()\n",
    "X_test_bup = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train))\n",
    "print(len(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_matrix = []\n",
    "print('FEATURE TYPE = raw-data')\n",
    "lead_no = 1\n",
    "NO_SAMPLES = 4500\n",
    "for ii in range(len(list_fname)):\n",
    "    #-------------------------------------------------\n",
    "    # META DATA FEATURES\n",
    "    #-------------------------------------------------\n",
    "    tmp_smp_name = list_fname[ii][:-4]\n",
    "\n",
    "    print('ECG Sample Name:' ,ii,tmp_smp_name)\n",
    "\n",
    "\n",
    "    tmp_smp_mat = os.path.join(pth_data,tmp_smp_name+'.mat')\n",
    "    tmp_smp_hea = os.path.join(pth_data,tmp_smp_name+'.hea')\n",
    "\n",
    "    data, header_data = load_challenge_data(tmp_smp_mat)\n",
    "    # data - ecg data\n",
    "    # header_data - contains information such as fs, gain, etc.\n",
    "\n",
    "    tmp_sample_ecg_all = data # ECG from all the leads\n",
    "    tmp_sample_ecg_lead = data[lead_no-1]\n",
    "\n",
    "    features_samp = np.zeros((0, NO_SAMPLES))\n",
    "\n",
    "\n",
    "    if(len(tmp_sample_ecg_lead) > NO_SAMPLES):\n",
    "        features_samp = tmp_sample_ecg_lead[0:NO_SAMPLES]\n",
    "    else:\n",
    "        features_samp[0,0:len(tmp_sample_ecg_lead)] = tmp_sample_ecg_lead\n",
    "\n",
    "    features_matrix.append(features_samp)\n",
    "\n",
    "    del features_samp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(features_matrix))\n",
    "print(len(fname_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecg_feature_extract(pth_data, list_fname, feat_type):\n",
    "    features_matrix = []\n",
    "    #for ii in range(len(list_data)):\n",
    "    \n",
    "    if(feat_type == 'raw-data'):\n",
    "        print('FEATURE TYPE = raw-data')\n",
    "        lead_no = 1\n",
    "        NO_SAMPLES = 4500\n",
    "        for ii in range(len(list_fname)):\n",
    "            #-------------------------------------------------\n",
    "            # META DATA FEATURES\n",
    "            #-------------------------------------------------\n",
    "            tmp_smp_name = list_fname[ii][:-4]\n",
    "\n",
    "            print('ECG Sample Name:',tmp_smp_name)\n",
    "\n",
    "\n",
    "            tmp_smp_mat = os.path.join(pth_data,tmp_smp_name+'.mat')\n",
    "            tmp_smp_hea = os.path.join(pth_data,tmp_smp_name+'.hea')\n",
    "\n",
    "            data, header_data = load_challenge_data(tmp_smp_mat)\n",
    "            # data - ecg data\n",
    "            # header_data - contains information such as fs, gain, etc.\n",
    "            \n",
    "            tmp_sample_ecg_all = data # ECG from all the leads\n",
    "            tmp_sample_ecg_lead = data[lead_no-1]\n",
    "\n",
    "            features_samp = np.zeros((0, NO_SAMPLES))\n",
    "\n",
    "            \n",
    "            if(len(tmp_sample_ecg_lead) > NO_SAMPLES):\n",
    "                features_samp = tmp_sample_ecg_lead[0:NO_SAMPLES]\n",
    "            else:\n",
    "                features_samp[0,0:len(tmp_sample_ecg_lead)] = tmp_sample_ecg_lead\n",
    "                    \n",
    "            features_matrix.append(features_samp)\n",
    "\n",
    "            del features_samp\n",
    "            \n",
    "        return np.asarray(features_matrix)\n",
    "            \n",
    "    \n",
    "    else:\n",
    "        lead_no = 1\n",
    "        for ii in range(len(list_fname)):\n",
    "            #-------------------------------------------------\n",
    "            # META DATA FEATURES\n",
    "            #-------------------------------------------------\n",
    "            tmp_smp_name = list_fname[ii][:-4]\n",
    "\n",
    "            print('ECG Sample Name:',tmp_smp_name)\n",
    "\n",
    "\n",
    "            tmp_smp_mat = os.path.join(pth_data,tmp_smp_name+'.mat')\n",
    "            tmp_smp_hea = os.path.join(pth_data,tmp_smp_name+'.hea')\n",
    "\n",
    "            data, header_data = load_challenge_data(tmp_smp_mat)\n",
    "            # data - ecg data\n",
    "            # header_data - contains information such as fs, gain, etc. \n",
    "\n",
    "            tmp_hea = header_data[0].split(' ')\n",
    "            # print(tmp_hea)\n",
    "            # ['A0001', '12', '500', '7500', '16-Mar-2020', '19:07:01\\n']\n",
    "            ptID = tmp_hea[0] # 'A0001'\n",
    "            num_leads = int(tmp_hea[1]) # '12'\n",
    "            sample_Fs= int(tmp_hea[2]) # '500'\n",
    "            gain_lead = np.zeros(num_leads) # 1000\n",
    "\n",
    "            for ii in range(num_leads):\n",
    "                tmp_hea = header_data[ii+1].split(' ')\n",
    "                gain_lead[ii] = int(tmp_hea[2].split('/')[0])\n",
    "\n",
    "            # for testing, we included the mean age of 57 if the age is a NaN\n",
    "            # This value will change as more data is being released\n",
    "            for iline in header_data:\n",
    "                if iline.startswith('#Age'):\n",
    "                    tmp_age = iline.split(': ')[1].strip()\n",
    "                    tmp_sample_age = int(tmp_age if tmp_age != 'NaN' else 57)\n",
    "                elif iline.startswith('#Sex'):\n",
    "                    tmp_sex = iline.split(': ')[1]\n",
    "                    if tmp_sex.strip()=='Female':\n",
    "                        tmp_sample_sex =1\n",
    "                    else:\n",
    "                        tmp_sample_sex=0\n",
    "                elif iline.startswith('#Dx'):\n",
    "                    label = iline.split(': ')[1].split(',')[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            tmp_sample_ecg_all = data # ECG from all the leads\n",
    "            tmp_sample_ecg_lead = data[lead_no-1]\n",
    "            tmp_sample_ecg_g = gain_lead[lead_no-1]\n",
    "            tmp_sample_ecg_fs = sample_Fs\n",
    "            #------------------------------------------------------------\n",
    "            # R-Peaks Features\n",
    "            #------------------------------------------------------------\n",
    "            r_peaks_pnet,r_idx_pnet = detect_peaks(tmp_sample_ecg_lead,tmp_sample_ecg_fs,tmp_sample_ecg_g)\n",
    "\n",
    "            r_peaks_pnet = r_peaks_pnet.astype(int)\n",
    "            r_idx_pnet_sample = r_peaks_idx2sample(r_idx_pnet)\n",
    "\n",
    "\n",
    "            #------------------------------------------------------------\n",
    "            # R-Peaks Statistical Features\n",
    "            #------------------------------------------------------------\n",
    "            #   mean\n",
    "            mean_RR = np.mean(r_idx_pnet_sample/tmp_sample_ecg_fs)\n",
    "            mean_Peaks = np.mean(r_peaks_pnet*tmp_sample_ecg_g)\n",
    "\n",
    "            #   median\n",
    "            median_RR = np.median(r_idx_pnet_sample/tmp_sample_ecg_fs)\n",
    "            median_Peaks = np.median(r_peaks_pnet*tmp_sample_ecg_g)\n",
    "\n",
    "            #   standard deviation\n",
    "            std_RR = np.std(r_idx_pnet_sample/tmp_sample_ecg_fs*1000)\n",
    "            std_Peaks = np.std(r_peaks_pnet*tmp_sample_ecg_g)\n",
    "\n",
    "            #   variance\n",
    "            var_RR = stats.tvar(r_idx_pnet_sample/tmp_sample_ecg_fs*1000)\n",
    "            var_Peaks = stats.tvar(r_peaks_pnet*tmp_sample_ecg_g)\n",
    "\n",
    "            #   Skewness\n",
    "            skew_RR = stats.skew(r_idx_pnet_sample/tmp_sample_ecg_fs*1000)\n",
    "            skew_Peaks = stats.skew(r_peaks_pnet*tmp_sample_ecg_g)\n",
    "\n",
    "            #   Kurtosis\n",
    "            kurt_RR = stats.kurtosis(r_idx_pnet_sample/tmp_sample_ecg_fs*1000)\n",
    "            kurt_Peaks = stats.kurtosis(r_peaks_pnet*tmp_sample_ecg_g)\n",
    "\n",
    "            features_samp = np.hstack([tmp_sample_age,tmp_sample_sex,mean_RR,mean_Peaks,median_RR,median_Peaks,std_RR,std_Peaks,var_RR,var_Peaks,skew_RR,skew_Peaks,kurt_RR,kurt_Peaks])\n",
    "\n",
    "            features_matrix.append(features_samp)\n",
    "\n",
    "            del features_samp\n",
    "\n",
    "        return np.asarray(features_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ecg_feature_extract(pth_data, fname_train,'raw-data')\n",
    "X_valid = ecg_feature_extract(pth_data, fname_valid,'raw-data')\n",
    "X_test = ecg_feature_extract(pth_data, fname_test,'raw-data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data labels into matrix form i.e. [no of samples x no of output classes]\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(Y_train)\n",
    "# lb.classes_\n",
    "Y_train = lb.transform(Y_train)\n",
    "Y_valid = lb.transform(Y_valid)\n",
    "Y_test = lb.transform(Y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_prepare = {\n",
    "    \"method\": \"single+classifier1\", # string\n",
    "    \"leads\": [1] # list\n",
    "}\n",
    "\n",
    "X_train = data_prepare_list2matrix(X_train,param_prepare)\n",
    "X_valid = data_prepare_list2matrix(X_valid,param_prepare)\n",
    "X_test = data_prepare_list2matrix(X_test,param_prepare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_valid = np.reshape(X_valid, (X_valid.shape[0], 1, X_valid.shape[1]))\n",
    "X_test = np.reshape(X_valid, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dim = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create and fit the LSTM network\n",
    "batch_size = 64\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, return_sequences=True, input_shape=(1, feat_dim)))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(OUTPUT_CLASSES, activation='softmax'))\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0, patience=50, verbose=1, mode='auto')\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs=100, batch_size=batch_size, validation_data=(X_valid, Y_valid), verbose=2, shuffle=False, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ecg_lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = model.predict(X_test)\n",
    "pred_classes = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = accuracy_score(Y_test, lb.transform(pred_classes))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import (Input, Conv1D, MaxPooling1D, Dropout,\n",
    "                          BatchNormalization, Activation, Add,\n",
    "                          Flatten, Dense)\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualUnit(object):\n",
    "    \"\"\"Residual unit block (unidimensional).\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_samples_out: int\n",
    "        Number of output samples.\n",
    "    n_filters_out: int\n",
    "        Number of output filters.\n",
    "    kernel_initializer: str, otional\n",
    "        Initializer for the weights matrices. See Keras initializers. By default it uses\n",
    "        'he_normal'.\n",
    "    dropout_rate: float [0, 1), optional\n",
    "        Dropout rate used in all Dropout layers. Default is 0.8\n",
    "    kernel_size: int, optional\n",
    "        Kernel size for convolutional layers. Default is 17.\n",
    "    preactivation: bool, optional\n",
    "        When preactivation is true use full preactivation architecture proposed\n",
    "        in [1]. Otherwise, use architecture proposed in the original ResNet\n",
    "        paper [2]. By default it is true.\n",
    "    postactivation_bn: bool, optional\n",
    "        Defines if you use batch normalization before or after the activation layer (there\n",
    "        seems to be some advantages in some cases:\n",
    "        https://github.com/ducha-aiki/caffenet-benchmark/blob/master/batchnorm.md).\n",
    "        If true, the batch normalization is used before the activation\n",
    "        function, otherwise the activation comes first, as it is usually done.\n",
    "        By default it is false.\n",
    "    activation_function: string, optional\n",
    "        Keras activation function to be used. By default 'relu'.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] K. He, X. Zhang, S. Ren, and J. Sun, \"Identity Mappings in Deep Residual Networks,\"\n",
    "           arXiv:1603.05027 [cs], Mar. 2016. https://arxiv.org/pdf/1603.05027.pdf.\n",
    "    .. [2] K. He, X. Zhang, S. Ren, and J. Sun, \"Deep Residual Learning for Image Recognition,\" in 2016 IEEE Conference\n",
    "           on Computer Vision and Pattern Recognition (CVPR), 2016, pp. 770-778. https://arxiv.org/pdf/1512.03385.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_samples_out, n_filters_out, kernel_initializer='he_normal',\n",
    "                 dropout_rate=0.8, kernel_size=17, preactivation=True,\n",
    "                 postactivation_bn=False, activation_function='relu'):\n",
    "        self.n_samples_out = n_samples_out\n",
    "        self.n_filters_out = n_filters_out\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.kernel_size = kernel_size\n",
    "        self.preactivation = preactivation\n",
    "        self.postactivation_bn = postactivation_bn\n",
    "        self.activation_function = activation_function\n",
    "\n",
    "    def _skip_connection(self, y, downsample, n_filters_in):\n",
    "        \"\"\"Implement skip connection.\"\"\"\n",
    "        # Deal with downsampling\n",
    "        if downsample > 1:\n",
    "            y = MaxPooling1D(downsample, strides=downsample, padding='same')(y)\n",
    "        elif downsample == 1:\n",
    "            y = y\n",
    "        else:\n",
    "            raise ValueError(\"Number of samples should always decrease.\")\n",
    "        # Deal with n_filters dimension increase\n",
    "        if n_filters_in != self.n_filters_out:\n",
    "            # This is one of the two alternatives presented in ResNet paper\n",
    "            # Other option is to just fill the matrix with zeros.\n",
    "            y = Conv1D(self.n_filters_out, 1, padding='same',\n",
    "                       use_bias=False, kernel_initializer=self.kernel_initializer)(y)\n",
    "        return y\n",
    "\n",
    "    def _batch_norm_plus_activation(self, x):\n",
    "        if self.postactivation_bn:\n",
    "            x = Activation(self.activation_function)(x)\n",
    "            x = BatchNormalization(center=False, scale=False)(x)\n",
    "        else:\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation(self.activation_function)(x)\n",
    "        return x\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        \"\"\"Residual unit.\"\"\"\n",
    "        x, y = inputs\n",
    "        n_samples_in = y.shape[1].value\n",
    "        downsample = n_samples_in // self.n_samples_out\n",
    "        n_filters_in = y.shape[2].value\n",
    "        y = self._skip_connection(y, downsample, n_filters_in)\n",
    "        # 1st layer\n",
    "        x = Conv1D(self.n_filters_out, self.kernel_size, padding='same',\n",
    "                   use_bias=False, kernel_initializer=self.kernel_initializer)(x)\n",
    "        x = self._batch_norm_plus_activation(x)\n",
    "        if self.dropout_rate > 0:\n",
    "            x = Dropout(self.dropout_rate)(x)\n",
    "\n",
    "        # 2nd layer\n",
    "        x = Conv1D(self.n_filters_out, self.kernel_size, strides=downsample,\n",
    "                   padding='same', use_bias=False,\n",
    "                   kernel_initializer=self.kernel_initializer)(x)\n",
    "        if self.preactivation:\n",
    "            x = Add()([x, y])  # Sum skip connection and main connection\n",
    "            y = x\n",
    "            x = self._batch_norm_plus_activation(x)\n",
    "            if self.dropout_rate > 0:\n",
    "                x = Dropout(self.dropout_rate)(x)\n",
    "        else:\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Add()([x, y])  # Sum skip connection and main connection\n",
    "            x = Activation(self.activation_function)(x)\n",
    "            if self.dropout_rate > 0:\n",
    "                x = Dropout(self.dropout_rate)(x)\n",
    "            y = x\n",
    "        return [x, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Model ----- #\n",
    "kernel_size = 16\n",
    "kernel_initializer = 'he_normal'\n",
    "signal = Input(shape=(4096, 12), dtype=np.float32, name='signal')\n",
    "age_range = Input(shape=(6,), dtype=np.float32, name='age_range')\n",
    "is_male = Input(shape=(1,), dtype=np.float32, name='is_male')\n",
    "\n",
    "\n",
    "x = signal\n",
    "x = Conv1D(64, kernel_size, padding='same', use_bias=False,\n",
    "           kernel_initializer=kernel_initializer)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x, y = ResidualUnit(1024, 128, kernel_size=kernel_size,\n",
    "                    kernel_initializer=kernel_initializer)([x, x])\n",
    "x, y = ResidualUnit(256, 196, kernel_size=kernel_size,\n",
    "                    kernel_initializer=kernel_initializer)([x, y])\n",
    "x, y = ResidualUnit(64, 256, kernel_size=kernel_size,\n",
    "                    kernel_initializer=kernel_initializer)([x, y])\n",
    "x, _ = ResidualUnit(16, 320, kernel_size=kernel_size,\n",
    "                    kernel_initializer=kernel_initializer)([x, y])\n",
    "x = Flatten()(x)\n",
    "diagn = Dense(6, activation='sigmoid', kernel_initializer=kernel_initializer)(x)\n",
    "model = Model(signal, diagn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x, y,\n",
    "            batch_size=batch_size,\n",
    "            epochs=70,\n",
    "            initial_epoch=0,  # If you are continuing a interrupted section change here\n",
    "            validation_split=args.val_split,\n",
    "            shuffle='batch',  # Because our dataset is an HDF5 file\n",
    "            callbacks=callbacks,\n",
    "            verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JUNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
